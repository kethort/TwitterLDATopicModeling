##################
##### P = Q ######
##################

>>> P = []
>>> Q = []
>>> for i in range(0, 99):
...     P.append(0.01)
...     Q.append(0.01)
... 
>>> print(np.array(P))
[ 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01]
>>> print(np.array(Q))
[ 0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01  0.01
  0.01  0.01  0.01]
>>> print(tweets_on_LDA.jensen_shannon_divergence(np.array(P), np.array(Q)))
0.0

#############################
##### P = reciprocal(Q) #####
#############################

>>> P = []
>>> Q = []
>>> for i in range(0, 99):
...     if i % 2 == 0:
...         P.append(0.02)
...         Q.append(0)
...     else:
...         Q.append(0.02)
...         P.append(0)
... 
>>> print(np.array(P))
[ 0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.
  0.02  0.    0.02]
>>> print(np.array(Q))
[ 0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02  0.    0.02
  0.    0.02  0.  ]
>>> print(tweets_on_LDA.jensen_shannon_divergence(np.array(P), np.array(Q)))
0.69314718056

###########################
##### P = not(Q) #####
###########################
>>> P = []
>>> Q = []
>>> for i in range(0, 99):
...     P.append(0)
...     Q.append(1)
... 
>>> print(np.array(P))
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
>>> print(np.array(Q))
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
>>> print(tweets_on_LDA.jensen_shannon_divergence(np.array(P), np.array(Q)))
inf


